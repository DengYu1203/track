{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user/deng/catkin_deng/src/track/DBSCAN_Train/radarScenes_v5_Nmin\n"
     ]
    }
   ],
   "source": [
    "code_path = os.getcwd()\n",
    "input_dir = os.path.join(code_path,'radarScenes_v5_Nmin')\n",
    "print(input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_read():\n",
    "  print(\"Reading directory:\",input_dir)\n",
    "  files = os.listdir(input_dir)\n",
    "  files.sort(key=lambda x:x[:11])\n",
    "  print('Training Sequence:',len(files))\n",
    "  Nmin = []\n",
    "  TrainX = []\n",
    "  for filename in files:\n",
    "    csv_path = os.path.join(input_dir,filename)\n",
    "    with open(csv_path,newline='') as csv_file:\n",
    "      rows = csv.reader(csv_file)\n",
    "      first = True\n",
    "      for row in rows:\n",
    "        if first:\n",
    "          first = False\n",
    "          continue\n",
    "        if str(row).find('nan') != -1 or str(row).find('inf') != -1:\n",
    "          continue\n",
    "        Nmin.append(int(row[2]))\n",
    "        input_row = []\n",
    "        input_row.append(float(row[4])/int(row[11])) # vel slot 0\n",
    "        input_row.append(float(row[5])/int(row[11])) # vel slot 1\n",
    "        input_row.append(float(row[6])/int(row[11])) # vel slot 2\n",
    "        input_row.append(float(row[7])/int(row[11])) # vel slot 3\n",
    "        input_row.append(float(row[8])/int(row[11])) # vel slot 4\n",
    "        input_row.append(float(row[9])/int(row[11])) # vel slot 5\n",
    "        input_row.append(int(row[11])) # current scan num\n",
    "\n",
    "        TrainX.append(input_row)\n",
    "  NminMatrix = np.asarray(Nmin)\n",
    "  NminMatrix.reshape(len(Nmin),1)\n",
    "  # Nmin_min = np.min(NminMatrix)\n",
    "  # Nmin_max = np.max(NminMatrix)\n",
    "  # NminMatrix = (NminMatrix-Nmin_min)/(Nmin_max-Nmin_min)\n",
    "  print('Target:',NminMatrix[0])\n",
    "  print('Input:',TrainX[0])\n",
    "  TrainMatrix = np.asarray(TrainX)\n",
    "  X_train, X_test, Y_train, Y_test = model_selection.train_test_split(np.array(TrainMatrix), np.array(NminMatrix), test_size=0.2)\n",
    "  print('Training Element: vel slot 0~5, current scan num; Training Target: Nmin in iou 0.3')\n",
    "  return X_train, X_test, Y_train, Y_test, TrainMatrix, NminMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading directory: /home/user/deng/catkin_deng/src/track/DBSCAN_Train/radarScenes_v5_Nmin\n",
      "Training Sequence: 112\n",
      "Target: 2\n",
      "Input: [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 300]\n",
      "Training Element: vel slot 0~5, current scan num; Training Target: Nmin in iou 0.3\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test, X_total, Y_total = csv_read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model,name):\n",
    "    out_path = os.path.join(code_path,name+'.sav')\n",
    "    pickle.dump(model,open(out_path,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model,X_test,Y_test):\n",
    "    predict_y_test = model.predict(X_test)\n",
    "    print('Test r-score: ',metrics.r2_score(Y_test,predict_y_test))\n",
    "    print('Test mean: ',metrics.mean_squared_error(Y_test,predict_y_test))\n",
    "    print(Y_test)\n",
    "    print(predict_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(name):\n",
    "    load_path = os.path.join(code_path,name+'.sav')\n",
    "    return pickle.load(open(load_path, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_model_name = 'Nmin_MLP_model_logistic_v3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Net'+training_model_name+'!')\n",
    "model = MLPRegressor(hidden_layer_sizes=200, max_iter=300, activation='logistic')\n",
    "model.fit(X_train,Y_train)\n",
    "save_model(model, training_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.get_params())\n",
    "evaluate_model(model,X_test,Y_test)\n",
    "plt.plot(model.loss_curve_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    model.partial_fit(X_train,Y_train)\n",
    "    print('End training iter',i)\n",
    "    save_model(model,training_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#v2 result\n",
    "print(model.get_params())\n",
    "evaluate_model(model,X_test,Y_test)\n",
    "plt.plot(model.loss_curve_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v1 result\n",
    "print(model.get_params())\n",
    "evaluate_model(model,X_test,Y_test)\n",
    "plt.plot(model.loss_curve_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intercepts = np.array(model.intercepts_)\n",
    "print(intercepts.shape)\n",
    "print(repr(intercepts[0]))\n",
    "print(repr(intercepts[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = np.array(model.coefs_)\n",
    "print(coef[0].shape)\n",
    "print(coef[1].shape)\n",
    "print(repr(coef[1].reshape(200)))\n",
    "# print(model.coefs_)\n",
    "for i in range(7):\n",
    "    print(repr(coef[0][i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "# v2: use Nmin in iou>=0.5, v3: use Nmin in iou>=0.3\n",
    "training_model_name_2 = 'Nmin_Linear_model_v3'\n",
    "model2 = LinearRegression().fit(X_total, Y_total)\n",
    "save_model(model2,training_model_name_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'copy_X': True, 'fit_intercept': True, 'n_jobs': None, 'normalize': False}\n",
      "Test r-score:  0.16316787452293802\n",
      "Test mean:  3.510938840546214\n",
      "[4 2 2 ... 5 3 9]\n",
      "[4.49625754 4.10634395 2.95595983 ... 3.2554395  4.11950623 7.82684467]\n"
     ]
    }
   ],
   "source": [
    "print(model2.get_params())\n",
    "evaluate_model(model2,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([-7.64444524e+00,  1.78340216e+01,  2.02924245e+00, -6.12427851e-01,\n",
      "       -1.78487167e+01,  6.24232575e+00,  2.09028092e-03])\n",
      "9.781014951107098\n"
     ]
    }
   ],
   "source": [
    "linear_coef = model2.coef_\n",
    "print(repr(linear_coef))\n",
    "print(repr(model2.intercept_))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5ef1a8950ce0fa2c598227f08e612ec9b24c4b828383aadb3ebd7f2669e1e894"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 ('DL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}